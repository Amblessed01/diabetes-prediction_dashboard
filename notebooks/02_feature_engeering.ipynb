{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcbf2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 02: FEATURE ENGINEERING + SPLITS ===\n",
      "Loaded cleaned dataset: (96146, 14)\n",
      "Columns: ['gender', 'age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'smoking_No Info', 'smoking_current', 'smoking_ever', 'smoking_former', 'smoking_never', 'smoking_not current', 'diabetes']\n",
      "Smoking dummy columns already exist. Using them as-is.\n",
      "After feature engineering: (96146, 20)\n",
      "Train: (67302, 19) (67302,)\n",
      "Val:   (20190, 19) (20190,)\n",
      "Test:  (8654, 19) (8654,)\n",
      "\n",
      "Saved engineered datasets:\n",
      "C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_train_data.csv\n",
      "C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_val_data.csv\n",
      "C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_test_data.csv\n",
      "\n",
      "Sanity Check: Expected smoking dummy columns present?\n",
      "smoking_No Info \n",
      "smoking_current \n",
      "smoking_ever \n",
      "smoking_former \n",
      "smoking_never \n",
      "smoking_not current \n",
      "\n",
      "Feature engineering complete. Next I run 03_model_development.ipynb to train LightGBM and save artifacts.\n"
     ]
    }
   ],
   "source": [
    "# 02_feature_engineering.ipynb\n",
    "# I build engineered features, handle categorical encoding safely,\n",
    "# create train/val/test splits, and save engineered CSVs.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\n=== 02: FEATURE ENGINEERING + SPLITS ===\")\n",
    "\n",
    "    CLEANED_PATH = r\"C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\cleaned_diabetes_data.csv\"\n",
    "\n",
    "    TRAIN_OUT = r\"C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_train_data.csv\"\n",
    "    VAL_OUT   = r\"C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_val_data.csv\"\n",
    "    TEST_OUT  = r\"C:\\Users\\User\\Desktop\\OSIRI UNIVERSITY Files\\diabetes_prediction_dashboard\\engineered_test_data.csv\"\n",
    "\n",
    "    \n",
    "    #  Load cleaned dataset\n",
    "    \n",
    "    thankgod_israel = pd.read_csv(CLEANED_PATH)\n",
    "    print(\"Loaded cleaned dataset:\", thankgod_israel.shape)\n",
    "    print(\"Columns:\", list(thankgod_israel.columns))\n",
    "\n",
    "    \n",
    "    #  Minimal required columns check\n",
    "    \n",
    "    required_cols_min = [\n",
    "        \"gender\",\n",
    "        \"age\",\n",
    "        \"hypertension\",\n",
    "        \"heart_disease\",\n",
    "        \"bmi\",\n",
    "        \"HbA1c_level\",\n",
    "        \"blood_glucose_level\",\n",
    "        \"diabetes\",\n",
    "    ]\n",
    "\n",
    "    missing_cols = [c for c in required_cols_min if c not in thankgod_israel.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    \n",
    "    #  Gender encoding (robust: handles already-numeric)\n",
    "    \n",
    "    if thankgod_israel[\"gender\"].dtype == \"object\":\n",
    "        gender_map = {\"Female\": 0, \"Male\": 1, \"Other\": 2}\n",
    "        thankgod_israel[\"gender\"] = thankgod_israel[\"gender\"].map(gender_map).fillna(2).astype(int)\n",
    "    else:\n",
    "        # if already numeric, ensure integer\n",
    "        thankgod_israel[\"gender\"] = thankgod_israel[\"gender\"].fillna(2).astype(int)\n",
    "\n",
    "   \n",
    "    #  Smoking history encoding (THIS FIXES YOUR ERROR)\n",
    "    #    - If smoking_history exists -> one-hot encode\n",
    "    #    - Else if already dummy columns exist -> keep\n",
    "    #    - Else -> create expected dummy columns with zeros\n",
    "\n",
    "    expected_smoking_cols = [\n",
    "        \"smoking_No Info\",\n",
    "        \"smoking_current\",\n",
    "        \"smoking_ever\",\n",
    "        \"smoking_former\",\n",
    "        \"smoking_never\",\n",
    "        \"smoking_not current\",\n",
    "    ]\n",
    "\n",
    "    if \"smoking_history\" in thankgod_israel.columns:\n",
    "        # Normalize and one-hot encode\n",
    "        thankgod_israel[\"smoking_history\"] = thankgod_israel[\"smoking_history\"].astype(str).str.strip()\n",
    "\n",
    "        smoking_dummies = pd.get_dummies(thankgod_israel[\"smoking_history\"], prefix=\"smoking\")\n",
    "\n",
    "        # Ensure expected columns exist\n",
    "        for col in expected_smoking_cols:\n",
    "            if col not in smoking_dummies.columns:\n",
    "                smoking_dummies[col] = 0\n",
    "\n",
    "        # Merge + drop original\n",
    "        thankgod_israel = pd.concat(\n",
    "            [thankgod_israel.drop(columns=[\"smoking_history\"]), smoking_dummies[expected_smoking_cols]],\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"Smoking history encoded from 'smoking_history' column.\")\n",
    "\n",
    "    else:\n",
    "        # smoking_history not present: check if dummy cols already exist\n",
    "        already_present = [c for c in expected_smoking_cols if c in thankgod_israel.columns]\n",
    "\n",
    "        if len(already_present) == len(expected_smoking_cols):\n",
    "            print(\"Smoking dummy columns already exist. Using them as-is.\")\n",
    "        else:\n",
    "            # create missing smoking dummy cols as zeros\n",
    "            for col in expected_smoking_cols:\n",
    "                if col not in thankgod_israel.columns:\n",
    "                    thankgod_israel[col] = 0\n",
    "            print(\"No smoking_history column found; created missing smoking dummy columns as zeros.\")\n",
    "\n",
    "    \n",
    "    # 5) Feature engineering \n",
    "\n",
    "    thankgod_israel[\"age_bmi_interaction\"] = thankgod_israel[\"age\"] * thankgod_israel[\"bmi\"]\n",
    "    thankgod_israel[\"hba1c_glucose_interaction\"] = thankgod_israel[\"HbA1c_level\"] * thankgod_israel[\"blood_glucose_level\"]\n",
    "\n",
    "    thankgod_israel[\"age_squared\"] = thankgod_israel[\"age\"] ** 2\n",
    "    thankgod_israel[\"bmi_squared\"] = thankgod_israel[\"bmi\"] ** 2\n",
    "    thankgod_israel[\"hba1c_squared\"] = thankgod_israel[\"HbA1c_level\"] ** 2\n",
    "\n",
    "    thankgod_israel[\"risk_score\"] = (\n",
    "        (thankgod_israel[\"age\"] * 0.3)\n",
    "        + (thankgod_israel[\"bmi\"] * 0.2)\n",
    "        + (thankgod_israel[\"HbA1c_level\"] * 0.4)\n",
    "        + (thankgod_israel[\"blood_glucose_level\"] * 0.1)\n",
    "    )\n",
    "\n",
    "    print(\"After feature engineering:\", thankgod_israel.shape)\n",
    "\n",
    "    \n",
    "    # 6) Split train/val/test (stratified)\n",
    "    \n",
    "    X = thankgod_israel.drop(columns=[\"diabetes\"])\n",
    "    y = thankgod_israel[\"diabetes\"].astype(int)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape, y_train.shape)\n",
    "    print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "    print(\"Test: \", X_test.shape, y_test.shape)\n",
    "\n",
    "    \n",
    "    #  Save engineered splits\n",
    "  \n",
    "    engineered_train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "    engineered_val   = pd.concat([X_val.reset_index(drop=True), y_val.reset_index(drop=True)], axis=1)\n",
    "    engineered_test  = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    engineered_train.to_csv(TRAIN_OUT, index=False)\n",
    "    engineered_val.to_csv(VAL_OUT, index=False)\n",
    "    engineered_test.to_csv(TEST_OUT, index=False)\n",
    "\n",
    "    print(\"\\nSaved engineered datasets:\")\n",
    "    print(TRAIN_OUT)\n",
    "    print(VAL_OUT)\n",
    "    print(TEST_OUT)\n",
    "\n",
    "\n",
    "    # Sanity checks: confirm all expected columns exist\n",
    "   \n",
    "    print(\"\\nSanity Check: Expected smoking dummy columns present?\")\n",
    "    for col in expected_smoking_cols:\n",
    "        print(col, \"\" if col in engineered_train.columns else \"\")\n",
    "\n",
    "    print(\"\\nFeature engineering complete. Next I run 03_model_development.ipynb to train LightGBM and save artifacts.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
